{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport keras\nimport tensorflow\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense", "metadata": {"id": "67599777-d2f9-463d-9497-f611b40a112f"}, "outputs": [], "execution_count": 4}, {"cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='2DoIA_RY-NZbBNtfW0tKDioviuUlWs8dgyfsusnCraB1',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us-south.cloud-object-storage.appdomain.cloud')\n\nbucket = 'khushiproject-donotdelete-pr-wuxgvyqdljvlja'\nobject_key = 'tweet_emotions.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head(10)", "metadata": {"id": "7669e7fc-622b-4dc2-bd31-c1c8f9cc365d"}, "outputs": [{"execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "     tweet_id   sentiment                                            content\n0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n2  1956967696     sadness                Funeral ceremony...gloomy friday...\n3  1956967789  enthusiasm               wants to hang out with friends SOON!\n4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n5  1956968477       worry  Re-pinging @ghostridah14: why didn't you go to...\n6  1956968487     sadness  I should be sleep, but im not! thinking about ...\n7  1956968636       worry               Hmmm. http://www.djhero.com/ is down\n8  1956969035     sadness            @charviray Charlene my love. I miss you\n9  1956969172     sadness         @kelcouch I'm sorry  at least it's Friday?", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>wants to hang out with friends SOON!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1956968477</td>\n      <td>worry</td>\n      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1956968487</td>\n      <td>sadness</td>\n      <td>I should be sleep, but im not! thinking about ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1956968636</td>\n      <td>worry</td>\n      <td>Hmmm. http://www.djhero.com/ is down</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1956969035</td>\n      <td>sadness</td>\n      <td>@charviray Charlene my love. I miss you</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1956969172</td>\n      <td>sadness</td>\n      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}], "execution_count": 5}, {"cell_type": "code", "source": "texts = df[\"content\"].tolist()\nlabels = df[\"sentiment\"].tolist()", "metadata": {"id": "3ab6dbd2-bbe2-473d-8a28-1c804d3e8103"}, "outputs": [], "execution_count": 6}, {"cell_type": "code", "source": "# Tokenize the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(texts)", "metadata": {"id": "0d85a558-1dc3-4937-9330-8c8229b2303f"}, "outputs": [], "execution_count": 7}, {"cell_type": "code", "source": "sequences = tokenizer.texts_to_sequences(texts)\nmax_length = max([len(seq) for seq in sequences])\npadded_sequences = pad_sequences(sequences, maxlen=max_length)", "metadata": {"id": "266cc3ad-f413-47d9-bc29-680a56c6df82"}, "outputs": [], "execution_count": 9}, {"cell_type": "code", "source": "# Encode the string labels to integers\nlabel_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(labels)", "metadata": {"id": "cde0363e-6075-4a79-995c-004abf79d5bd"}, "outputs": [], "execution_count": 10}, {"cell_type": "code", "source": "# One-hot encode the labels\none_hot_labels = keras.utils.to_categorical(labels)", "metadata": {"id": "d115d95e-71fb-468c-9368-77eefca13737"}, "outputs": [], "execution_count": 11}, {"cell_type": "code", "source": "# Split the data into training and testing sets\nxtrain, xtest, ytrain, ytest = train_test_split(padded_sequences,one_hot_labels,test_size=0.2)", "metadata": {"id": "6716c74c-df87-461a-b31a-dcfd0c53f4b1"}, "outputs": [], "execution_count": 12}, {"cell_type": "code", "source": "# Define the model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=len(tokenizer.word_index) + 1, \n                    output_dim=128, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(Dense(units=128, activation=\"relu\"))\nmodel.add(Dense(units=len(one_hot_labels[0]), activation=\"softmax\"))\n\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.fit(xtrain, ytrain, epochs=10, batch_size=32, validation_data=(xtest, ytest))", "metadata": {"id": "17f6e8aa-a9f8-407d-8ef3-9621dd7d6b5a"}, "outputs": [{"name": "stdout", "text": "Epoch 1/10\n1000/1000 [==============================] - 51s 50ms/step - loss: 2.0118 - accuracy: 0.3058 - val_loss: 1.9272 - val_accuracy: 0.3288\nEpoch 2/10\n1000/1000 [==============================] - 50s 50ms/step - loss: 1.3076 - accuracy: 0.5777 - val_loss: 2.2908 - val_accuracy: 0.2930\nEpoch 3/10\n1000/1000 [==============================] - 51s 51ms/step - loss: 0.3496 - accuracy: 0.9028 - val_loss: 2.9938 - val_accuracy: 0.2726\nEpoch 4/10\n1000/1000 [==============================] - 51s 51ms/step - loss: 0.1243 - accuracy: 0.9682 - val_loss: 3.2770 - val_accuracy: 0.2570\nEpoch 5/10\n1000/1000 [==============================] - 51s 51ms/step - loss: 0.0756 - accuracy: 0.9808 - val_loss: 3.6563 - val_accuracy: 0.2562\nEpoch 6/10\n1000/1000 [==============================] - 52s 52ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 3.9390 - val_accuracy: 0.2585\nEpoch 7/10\n1000/1000 [==============================] - 51s 51ms/step - loss: 0.0449 - accuracy: 0.9880 - val_loss: 4.1499 - val_accuracy: 0.2605\nEpoch 8/10\n1000/1000 [==============================] - 51s 51ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 4.2720 - val_accuracy: 0.2477\nEpoch 9/10\n1000/1000 [==============================] - 53s 53ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 4.6498 - val_accuracy: 0.2561\nEpoch 10/10\n1000/1000 [==============================] - 51s 51ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 5.2366 - val_accuracy: 0.2601\n", "output_type": "stream"}, {"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "<keras.src.callbacks.History at 0x7ff33d251190>"}, "metadata": {}}], "execution_count": 13}, {"cell_type": "code", "source": "input_text = \"She didn't come today because she lost her dog yestertay!\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "255ad961-a0b5-4e25-81f7-ac08ff3e730b"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 62ms/step\n['neutral']\n", "output_type": "stream"}], "execution_count": 14}, {"cell_type": "code", "source": "input_text = \"i kept smiling throughout the day\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "88190cae-e6c3-4e26-af9e-df315bc2e5e3"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 18ms/step\n['neutral']\n", "output_type": "stream"}], "execution_count": 15}, {"cell_type": "code", "source": "input_text = \"He was crying the whole night\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "57b80319-42e6-482c-b96f-70b2a7d1a042"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 24ms/step\n['love']\n", "output_type": "stream"}], "execution_count": 16}, {"cell_type": "code", "source": "input_text = \"He got suspended by the teachers for misbehaving\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "a3dccefe-7f1d-42de-a516-9d24d0807f76"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 19ms/step\n['worry']\n", "output_type": "stream"}], "execution_count": 17}, {"cell_type": "code", "source": "input_text = \"The teachers were mesmerised by the results\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "259af9a5-e073-4a93-93d4-013792802cad"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 19ms/step\n['happiness']\n", "output_type": "stream"}], "execution_count": 18}, {"cell_type": "code", "source": "input_text = \"It started raining, the moment we stepped out\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "872fbb73-5a34-474e-9a9f-8acb4ced3e1d"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 19ms/step\n['neutral']\n", "output_type": "stream"}], "execution_count": 19}, {"cell_type": "code", "source": "input_text = \"She didn't come today because her dog died yestertay!\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "f4e933de-5520-46cc-bd8e-0df17d58222f"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 19ms/step\n['neutral']\n", "output_type": "stream"}], "execution_count": 20}, {"cell_type": "code", "source": "input_text = \"She didn't come today because she went to a funeral yestertay!\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "3d0f8da6-c99a-42fb-b7ff-4cd90a772fa7"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 18ms/step\n['worry']\n", "output_type": "stream"}], "execution_count": 21}, {"cell_type": "code", "source": "input_text = \"I shoule be sleeping right now instead of crying!\"\n\n# Preprocess the input text\ninput_sequence = tokenizer.texts_to_sequences([input_text])\npadded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\nprediction = model.predict(padded_input_sequence)\npredicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\nprint(predicted_label)", "metadata": {"id": "7d8cc7de-8238-4581-9941-22e417586c3f"}, "outputs": [{"name": "stdout", "text": "1/1 [==============================] - 0s 18ms/step\n['neutral']\n", "output_type": "stream"}], "execution_count": 22}, {"cell_type": "code", "source": "", "metadata": {"id": "37927249-5741-4f9a-ac95-0190ddb698a2"}, "outputs": [], "execution_count": null}]}